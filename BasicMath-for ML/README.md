# Basic-Math-Review- and-applying-it-using-ML

This is to provide a review and analysis of my math skills foundation and coding foundation, in regard to the upcoming FA23 semester to showcase my stronger and newer mathematical foundation.

In this RepoI Demonstrated Basics of **Algebra,Calculus(using Precalc) ,Statistics and Probability.**

# Why ML?
There are many reasons why the mathematics of Machine Learning is important and I will highlight some of them below:

1. Selecting the right algorithm which includes giving considerations to accuracy, training time, model complexity, number of parameters and number of features.

2. Choosing parameter settings and validation strategies.

3. Identifying underfitting and overfitting by understanding the Bias-Variance tradeoff.

4. Estimating the right confidence interval and uncertainty.

# What lead me to do this? Personal Agenda 
As I was struggling wihtin my freshman due to unforseen life circumstances and a discovery of having dyscalculia, it explained why my math foundation wasn't even close to being on par with my peers. Thus, instead of risking being possibly even more behind I decided to switch majors. However, within the past few months, I realized how much I enjoy being able to create things and analyze other lines of codes and projects to create things like this Repo for others who may need this review due to setbacks like myself. So now I'm making this in an attempt to showcase how I've been working to stregthen my mathematical foundation to be successful with my courses going forward. 

If a section confuses you or you're wondering where I did my research for the formulas. I quite literally just read Precalculus, Calculus and Statistics for Dummies about 4 times each and started working on this(they're fairly short works of text, so if possible I'd recommend them before jumping in to the things I've put in this repo).So I would check there, I believe they have a cheet sheet with the formulas online so you don't have to purchase a book unless you choose to. Yet, I've also included a cheet sheet for all the topics I'll be covering. 


# Probability Theory and Statistics:
Machine Learning and Statistics aren’t very different fields. Actually, someone recently defined Machine Learning as ‘doing statistics on a Mac’. Some of the fundamental Statistical and Probability Theory needed for ML are Combinatorics, Probability Rules & Axioms, Bayes’ Theorem, Random Variables, Variance and Expectation, Conditional and Joint Distributions, Standard Distributions (Bernoulli, Binomial, Multinomial, Uniform and Gaussian), Moment Generating Functions, Maximum Likelihood Estimation (MLE), Prior and Posterior, Maximum a Posteriori Estimation (MAP) and Sampling Methods.

# Multivariate Calculus: 
Some of the necessary topics include Differential and Integral Calculus, Partial Derivatives, Vector-Values Functions, Directional Gradient, Hessian, Jacobian, Laplacian and Lagrangian Distribution.

# Algorithms and Complex Optimizations:
This is important for understanding the computational efficiency and scalability of our Machine Learning Algorithm and for exploiting sparsity in our datasets. Knowledge of data structures (Binary Trees, Hashing, Heap, Stack etc), Dynamic Programming, Randomized & Sublinear Algorithm, Graphs, Gradient/Stochastic Descents and Primal-Dual methods are needed.

# Others: 
This comprises of other Math topics not covered in the four major areas described above. They include Real and Complex Analysis (Sets and Sequences, Topology, Metric Spaces, Single-Valued and Continuous Functions, Limits, Cauchy Kernel, Fourier Transforms), Information Theory (Entropy, Information Gain), Function Spaces and Manifolds.

## Summer Semester 2023 - Jardin Dantzler 